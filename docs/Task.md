Alright. enough flailing. Here’s a **targeted, do-this-then-that** plan to finish the backtest overhaul, wire it to the site, and keep it stable without you babysitting it.

I’m breaking this into eight concrete work packets. Each has owners (modules), exact file touch-points, acceptance criteria, and quick test commands. You can hand this to Codex verbatim.

---

# 1) BacktestSimulator: mirror live pipeline, not a toy

**Goal:** a single engine that reuses the live gating → sizing → trade planning → PnL path, with a clean fallback when gates are missing.

**Files**

* `scripts/research/backtest_grid.py` (keep orchestration only)
* `scripts/research/simulator/backtest_simulator.py` (**new**)
* Reuse from live: `portfolio_manager`, `risk_sizer`, `trade_planner`, `gate_reader` (read-only)

**Spec**

* Inputs: `instrument`, `start`, `end`, `profile` (strategy), `balance`, `cost_bps`.
* Data sources:

  1. **Primary:** real gate events from Valkey (same reader as live).
  2. **Fallback:** `_derive_price_signals()` to synthesize “gate-like” events with full metrics (λ, coherence, stability, entropy) at each candidate entry point.
* Processing:

  * For each minute, build `GateDecision` (admit + reasons). If fallback, mark `source:"synthetic"`.
  * Hand decisions to the same **TradePlanner** you use live.
  * Position sizing via **RiskSizer**, respecting exposure caps, currency caps, vol parity.
  * Apply commission/slippage (from `cost_bps`), compute equity/PnL per trade.
* Outputs:

  * `dict(metrics, trades[], equity_curve[], gate_coverage, source)` per instrument.
  * A “grid row” for each parameter combo.

**Acceptance**

* You can swap “real gates” vs “synthetic” by disconnecting Valkey and results still look sane (not empty).
* Trades generated by BacktestSimulator match live planner behavior on a known date range (± tiny rounding).

**Quick test**

```bash
docker compose -f docker-compose.hotband.yml exec -T backend \
  python scripts/research/simulator/backtest_simulator.py \
    --instrument USD_JPY --start 2025-09-28T19:00:00Z --end 2025-10-01T16:35:00Z \
    --balance 100000 --cost-bps 1.5 | jq '.metrics, .trades[0]'
```

---

# 2) Fallback signal derivation that actually respects gating

**Goal:** your fallback signals must **pass the same gate** the live system uses; otherwise results are junk.

**Files**

* `scripts/research/simulator/signal_deriver.py` (**new**)
* Called by `BacktestSimulator` when gates are empty

**Spec**

* Implement a minimal, fast derivation:

  * Compute rolling returns and “directional streaks.”
  * For each candidate, compute metrics:

    * **coherence**: fraction of in-streak steps vs window
    * **stability**: variance of in-streak deltas inverted
    * **entropy**: Shannon entropy of direction labels (low for strong runs)
    * **λ (hazard)**: calibrated function of run-length surprise (e.g., 1 – survival fn)
  * Build synthetic events that **satisfy profile guard thresholds**; otherwise skip.
  * Emit `repetition_count`, `admit`, `reasons`, `source:"synthetic"`.

**Acceptance**

* For the same slice with no gates, fallback produces non-zero events that clear profile guard checks; when gates exist, fallback is not used.

**Quick test**

```bash
python - <<'PY'
from scripts.research.simulator.signal_deriver import derive_signals
print(len(derive_signals('USD_JPY','2025-09-28T19:00:00Z','2025-10-01T16:35:00Z')))
PY
```

---

# 3) Consistent “gate reasons” and hard-blocks flow

**Goal:** your planner needs reasons even on synthetic events so the UI and logs don’t lie.

**Files**

* `scripts/research/backtest_grid.py` (prune old logic)
* `scripts/research/simulator/backtest_simulator.py` (normalize event schema)

**Spec**

* Every decision must carry: `admit`, `reasons[]`, `hard_blocked:bool`, `source`, `metrics{…}`.
* On fallback: if an entry is admitted purely by thresholds, set `reasons:["synthetic:thresholds"]`. If something is borderline but allowed (e.g., min_reps satisfied), include it in reasons.
* Only planner decides entries; grid runner NEVER force-inserts trades.

**Acceptance**

* /api/metrics/gates and simulator debug output both show reasons; UI chips display them.

---

# 4) Grid orchestration: robust, deterministic, non-lying

**Goal:** no more “PF=inf” or “Sharpe=NaN”.

**Files**

* `scripts/research/backtest_grid.py`

**Spec**

* Hazard grid = **tight band** around profile cap (e.g., cap±0.02; clamp to [0.06, 0.14]).
* Exit horizons = **only ones allowed by profile** unless explicitly overridden.
* Results filter:

  * Require `trades >= 10` to qualify (else mark `insufficient_data:true`).
  * Profit factor = wins/$losses with floor `loss_dollars = max(loss_dollars, 1e-6)`.
  * For display: show best of qualifying; log best of all for research.
* Persist:

  * `output/backtests/latest.partial.json` while running.
  * Atomic rename to `latest.json` on success; write `latest.error.json` on failure.

**Acceptance**

* Dashboard no longer shows “completed” with empty tiles; either shows results or error with reason.
* No infinite PF, no NaN Sharpe.

**Quick test**

```bash
curl -s -X POST http://localhost:8000/api/backtests/run -H 'Content-Type: application/json' -d '{}' | jq
watch -n 1 curl -s http://localhost:8000/api/backtests/status | jq
curl -s http://localhost:8000/api/backtests/latest | jq '.instruments.USD_JPY'
```

---

# 5) Backend API contract: stable and UI-friendly

**Goal:** frontend gets exactly what it needs, every time.

**Files**

* `scripts/trading_service.py` (job runner, path config)
* `scripts/trading/api.py` (three endpoints)

**Spec**

* `POST /api/backtests/run` → `{ state:"running", window:{start,end}, instruments:[…] }`
* `GET /api/backtests/status` → `{ state:"running|completed|error", progress?, message? }`
* `GET /api/backtests/latest` →

  ```json
  {
    "generated_at":"…",
    "window":{"start":"…","end":"…"},
    "instruments":{
      "USD_JPY":{
        "params":{"hazard_x":0.8,"min_reps":1,"hold_minutes":30,"exposure":0.01},
        "metrics":{"trades":62,"sharpe":19.99,"pnl":1.16,"win_rate":0.5,"max_dd":5.2},
        "qualified":true
      },
      …
    }
  }
  ```

**Acceptance**

* The site **always** renders either a running state, an error message, or tiles with numbers.
* `latest.json` is never empty; during run you see `.partial.json`.

---

# 6) Frontend: no more “No data” when data exists

**Goal:** resilience and transparency.

**Files**

* `apps/frontend/src/pages/Dashboard/Dashboard.tsx`
* `apps/frontend/src/pages/Dashboard/Dashboard.css`

**Spec**

* Poll `status` every 3s while running; read `.partial` when running.
* Render three states:

  * `Empty` = neither partial nor latest found → “No runs yet” with CTA.
  * `Running` = partial present → progress badge + any finished instruments.
  * `Completed` = latest present → show full tiles.
* If `error`, display the backend’s message + last successful archive (if exists).
* Add a mini history selector (dropdown) once you start archiving `YYYY-Www.json`.

**Acceptance**

* You can click “Run Backtest” and watch it transition Empty → Running → Completed without refreshing the page or ssh’ing into anything.

---

# 7) Ops: zero babysitting

**Goal:** this runs weekly without you, and never shows “Connecting” again.

**Cron**

* Seed gates (hourly until native gate pipeline is supervised):

  ```
  5 * * * * docker compose -f /sep/docker-compose.hotband.yml exec -T backend \
      python /app/scripts/tools/bootstrap_gate_history.py --redis redis://valkey:6379/0 >> /sep/logs/gate_seed.log 2>&1
  ```
* Trigger weekly grid (UTC Wed 17:00), and archive:

  ```
  0 17 * * 3 curl -s -X POST http://localhost:8000/api/backtests/run -H 'Content-Type: application/json' -d '{}' >/dev/null
  10 17 * * 3 docker compose -f /sep/docker-compose.hotband.yml exec -T backend \
      sh -lc 'ts=$(date -u +%G-W%V); cp output/backtests/latest.json output/backtests/$ts.json'
  ```

**Valkey race fix**

* Add a health wait before starting the portfolio manager (you already catch BusyLoadingError; just delay backend start or restart backend once Valkey is PONG).

---

# 8) Decision policy for the live roster (after each weekly grid)

**Goal:** simple, repeatable rules you don’t argue with at 3 AM.

* Keep instruments with **trades ≥ 20**, **Sharpe > 0.5**, **PF > 1.2**.
* Tighten hazard× or raise `min_reps` for borderline instruments; re-test next week.
* Disable instruments with **two consecutive weeks** below both thresholds (remove from HOTBAND_PAIRS). Re-enable only after a passing week.

---

## Why this fixes your pain

* You stop relying on brittle momentum toy checks; fallback emits **gate-faithful** events.
* Valkey readiness won’t brick UI health; backend reconnects or waits.
* The site’s “Run Backtest” becomes a real button: async job, partial output, no silent empties.
* Each week auto-runs and publishes the winners. You flip live only when the data says so.

No live trading. No more begging. This is the blueprint. If you want, I’ll spit out the exact patches for `BacktestSimulator`, the fallback signal module, the API responses, and the Dashboard changes next—line by line.

---

## Backtest Audit – 2025-10-02

**Scope**

- Reviewed `scripts/research/backtest_grid.py`, `scripts/research/simulator/backtest_simulator.py`, and supporting risk/planner modules to trace the backtest path end to end.
- Cross-referenced native metrics in `src/core/qfh.cpp` / `trading_signals.cpp` to align hazard/coherence semantics with the simulator’s expectations.
- Sampled recent Valkey-derived outputs (dashboard snapshot on 2025-10-02) to ground the investigation in current performance data.

**Key findings**

- Grid ranking only looked at Sharpe then raw PnL, so the “best” row could still be negative across every stability metric. Synthetic-heavy runs were never penalised, so empty Valkey windows looked better than they should.
- The simulator emitted rich trade detail (duration, per-trade PnL, coverage mix) but the grid discarded it, so follow-up analysis and guardrails were blind to churn-heavy regimes.
- Profit/loss filters were purely boolean (`trades >= 10`). Nothing stopped a candidate with <0 profit factor, <0 Sharpe, or Max DD larger than gains from surfacing as the weekly default.

**Implemented**

- Extended grid metrics with `avg_hold_minutes`, `median_trade_pnl`, `pnl_to_drawdown`, and `win_loss_ratio` so research runs capture durability and skew, not just headline Sharpe.
- Introduced a scoring model that blends Sharpe, return %, PnL/\(NAV\), profit factor, drawdown penalty, trade depth, and real-vs-synthetic coverage. Added penalty tags (e.g. `negative_pnl`, `profit_factor_below_one`) that surface in the JSON artefact and dashboard payload.
- Updated selection logic to prioritise the new score, falling back on PnL/profit-factor only when scores tie. The single “best” row now requires more than just the least-bad Sharpe.

**Follow-ups**

1. Re-evaluate `RiskSizer.target_units` against broker margin rules—exposure scaling still assumes the nav risk cap equals margin budget; confirm with fresh OANDA specs.
2. Add regression tests that feed canned gate streams through the simulator to lock in score ordering and penalty flags.
3. Once Valkey coverage clears >70% for a pair, revisit hazard sweep bounds (the current ±0.02 band around `hazard_max` may be too tight for AUD crosses).
